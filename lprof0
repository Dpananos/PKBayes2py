Timer unit: 1e-06 s

Total time: 0.742494 s
File: /Users/demetri/Documents/PhD Code/PKBayes2py/scripts/tools/q_learning.py
Function: stage_2_optimization at line 70

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    70                                           def stage_2_optimization(S_2):
    71                                               
    72         1         16.0     16.0      0.0      tobs, yobs, theta, dose_times, dose_size = S_2    
    73                                               # Assuming we sampled the subject at tobs and got yobs, what would our posterior look like?
    74                                               # Fit the model to the observation (tobs, yobs) with dose schedule instantiated from Q_1
    75         1     308901.0 308901.0     41.6      predict = fit(t=tobs, y=yobs, theta=theta, dose_times=dose_times, dose_size=dose_size)
    76                                           
    77                                               # We will be splitting the time into two stages.  E.g 4 days on inital dose, 4 days after, etc.  Same number of days in two stages.
    78                                               # Likely be sampling near the end of the last day in stage 2.  This means I would need to predict over the same length of time.
    79                                               # We observe at t=tobs.  When is the next time a dose is taken?  It would be the first positive element of dose_times-tobs.
    80                                               # Negative values in the past, positive values in the future.
    81         1        193.0    193.0      0.0      next_dose_time_after_tobs_ix = np.argwhere((dose_times - tobs)>0).min()
    82         1          3.0      3.0      0.0      next_dose_time_after_tobs = float(dose_times[next_dose_time_after_tobs_ix]) #There is some problem here.  Json doesn't like numpy dtypes, so turn to float
    83                                           
    84         1          3.0      3.0      0.0      decision_point = int(len(dose_times)/2)
    85         1          3.0      3.0      0.0      tfin = dose_times[decision_point]+0.5
    86         1         11.0     11.0      0.0      tpred = np.arange(0.5, tfin , 0.5)
    87                                               # Make predictions of the dynamics.  Estimate the inital_condition (latent concentration a next_dose_time_after_tobs) as well as the dynamics under a unit dose
    88                                               # That way, the total dynamics under a new dose us initial_condition + new_dose_size*dynamics.
    89                                               # This logic comes from solving the PK ode for an arbitrary inital condition.
    90         1         43.0     43.0      0.0      dose_of_1s = np.ones_like(dose_times)
    91         1     364209.0 364209.0     49.1      initial_condition, dynamics = predict(tpred=tpred, new_dose_times=dose_times, new_dose_size=dose_of_1s, c0_time=next_dose_time_after_tobs)
    92                                           
    93                                           
    94                                               # Can't give someone negative mg.  Bound the dose.
    95         1          6.0      6.0      0.0      dose_bnds = [(0, None)]
    96                                               # Pick a dose size to start with.  Remember to multiplt the initial condition by this dose size so that we are estimating the  concentration at tobs.
    97         1         62.0     62.0      0.0      D_old = np.unique(dose_size)
    98         1      69033.0  69033.0      9.3      optim = minimize(Q_2, x0=D_old, args=([D_old*initial_condition, dynamics]), bounds=dose_bnds, method = 'L-BFGS-B')
    99                                               
   100                                               # Policty is the argmax
   101         1          8.0      8.0      0.0      π_2 = optim.x[0]
   102                                               
   103                                               # Undo the negative we did in the objective.
   104                                               # Value is the max
   105         1          2.0      2.0      0.0      expected_V_2 = -1*optim.fun 
   106                                               
   107         1          1.0      1.0      0.0      return π_2, expected_V_2