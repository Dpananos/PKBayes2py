\section{Limitations}

%We have examined six modes for making decisions.  The next mode improves on a deficiency of the previous mode in a natural manner, and so our experiment constitutes a kind of ablation study.  We believe the decision making aspect of our study extracts information in a responsible way and uses the best decision making methodology available.  That being said, the experiment is not without limitations.

The Bayesian model of the pharmacokinetics is integral to the methodology we present.  Any shortcomings in the model affect the quality of the decision and decision process.  Bayesian models are not as ubiquitous as other models in pharmacology, and so particular expertise is required for model development and evaluation.  That expertise increases the implementation burden of any decision process involving Bayesian models.  However, we demonstrate how one such model can be constructed in a past study \cite{pananos2020comparisons} and include open sourced code and data for practitioners to replicate our model fitting.

Additionally, the data required to construct a high quality Bayesian model of pharmacokinetics require multiple observations of a single patient over an extended time, preferably over multiple well timed doses with near perfect adherence.  Obtaining such data requires well organized efforts and is high burden for both investigators and participating subjects.  This makes acquiring a robust Bayesian model for use in dose personalization difficult. For this reason, our framework is not intended to replace prospective evaluation of personalized medicine programs; rather it is intended to estimate relative performance given existing evidence so that the most promising modes of personalization can be identified for potential implementation and further study.

\section{Conclusions}\label{ss:discussion}

%Including age, sex, weight, and creatinine in our Bayesian model improved the inferences from that model.  Though the predicted concentrations and estimates of uncertainty changed negligibly, the covariates explained residual confounding in the random effects. This results in a model which better explains the observed variation in the data and hence should generate more plausible data for simulation.

%In the following, we discuss the results of our case study and some broader potential implications for personalized medicine policy.

%Working subsection titles - not sure if they stay
%\subsection{Comparing Modes of Personalization}

As expected, modes of personalization that use more information result in lower regret (larger achieved rewards.)  The static Clinical Variables mode balances relatively low implementation burden with high reward. However, there is right skew in the distribution of regret, with some `outliers' who are at risk of obtaining less than half of their best possible return. If avoiding this risk is important, the Clinical Variables + One Adjustment mode may be preferable, even though it imposes additional burden.

The Optimal Sampling Time and Optimal Sequential Dosing modes use the same information as Clinical Variables + One Adjustment, but impose more burden on the patient and clinic. Both require samples be taken at specified times, and the second uses a more complex optimization procedure. Neither of these improved performance beyond the simpler modes in our study. There are two characteristics of our study that may explain this result. First, the clinical variables used are known to affect the pharmacokinetics of apixiban and are useful for predicting concentrations for static personalization, hence their use alone makes it possible to choose good doses. In other settings where clinical variables are not as predictive, we would expect dynamic personalization to have a bigger advantage. Second, the elimination rates $k_e$ in our study were relatively high. This means that the effect of an initial dose on levels at the time subsequent doses are taken (i.e., a day later) is relatively small, so that doses can be optimized largely independently. If this were not the case, optimization using Q-learning would be expected to be more important to ensure that initial doses were not too large to successfully adapt later.

\subsection{Future Work}

Because the data required to build reliable Bayesian pharmacokinetic models are difficult to collect in practice, research into developing these models from observational data may prove fruitful in extending this work. If clinics record data on measured blood concentrations, they may have dozens or hundreds of subjects with only one or two measurements per subject.  Moreover, the subjects in question may be on multiple drugs or have comorbidities which may affect the pharmacokinetics of the drug under study.  Additional research into constructing Bayesian models which can adjust for polypharmacy and comorbidities while learning an individual’s pharmacokinetics from a large but sparse sample would drive this work towards being easier to implement in practice.


% It is clear that there are tradeoffs between achieving a reward close to what is theoretically largest and taking on additional clinic and implementation burden, and that tradeoff should be examined on a case-by-case basis.  Context is crucial, and how we adapt to that context is perhaps a question in need of closer examination.  Traditional methods of personalization include conditioning only on a subject’s covariates (not unlike the Clinical Variables mode we present here).  But of course patients are not their age, sex, weight, and creatinine.  Additionally, safety information and best available practices might change in the future as more research on drugs is performed. Were new safety information to be published, the reward function may need to be re-designed, which may result in a new mode of personalization being more/less preferable or more/less feasible.  Any number of factors in flux can change the context in which personalization occurs, and that change in context may prompt for a re-evaluation in how personalization is done.

%We do not offer recommendations on how personalization for apixaban should be done because this depends on the context of the health system and population where such personalization would be deployed. Rather, we offer a framework for developing strategies of personalization and evaluating their performance against their implementation and patient and provider burden.  Analyses can be adapted where needed, either through the reward function, or by adjusting when the clinic is able to take measurements, or by including additional information such as genotype in the Bayesian model. Each of these can also be done within established systems when new evidence or data become available. Using this framework, clinics have flexibility to tailor their personalization to the populations they serve.

%Working subsection titles - not sure if they stay
%\subsection{Relating Results to Policy Decisions}



%An additional expertise burden is added as machine learning (used interchangeably with the term “artificial intelligence”) is adopted into personalized medicine initiatives.  Cutting edge machine learning models for prediction or decision making can be prohibitively burdensome to implement effectively. Failure to carefully implement a prediction model may result in pernicious bias inadvertently affecting subpopulations, as was found to be the case in algorithms for credit scoring \cite{barocas2016big}, crime prediction \cite{lum2016predict}, and hiring \cite{ajunwa2020paradox}.  A 2019 study found an instance of this bias in a widely used risk scoring algorithm in healthcare \cite{obermeyer2019dissecting}, demonstrating that despite the best intentions of those involved, the use of a model can lead to worse rather than better care if investigators are not careful in considering what sorts of bias may be present in the data used to train these models.  Implementation of new approaches and methods requires the close collaboration of experts in data science  with physicians, domain experts, and other stakeholders.  Close collaboration should allow for domain experts to identify what kinds of biases the data might have, and for data science experts to implement methods to help ameliorate that bias (or to admit the data are not fit for purpose).  The result of iterating on this collaborative process (wherein domain experts help inform the approaches methodologists take, and the methodologists provide model checks which help domain experts decide if decisions from the model are reasonable or suspicious) is a model which more closely aligns with domain expertise, a model which is sufficiently flexible to capture the true data generating mechanism, an effective use of data, a more transparent modelling process, and calibrated expectations surrounding algorithms and their abilities \cite{frohlich2018hype}.  Presently, this form of collaboration between methodologists and domain experts is not the norm, with development of machine learning solutions in healthcare being developed in silos \cite{wiens2019no}.  These burdens may be surmountable for some, but the question then turns to if the result is worth the expense.   Answering that question is difficult without an idea how the additional burden of collecting data, or implementing new algorithms, will benefit the clinic or the patient subject to inherent constraints. 




\section{Implications}

Any decision to implement personalized medicine must assess the costs and benefits of doing so. Despite the potential for personalized medicine to reduce health care costs \cite{looff2016economic,shabaruddin2015economic}, the cost of patient testing and monitoring, personnel, and training required to operate a personalized medicine clinic carry a burden, and it is not yet clear in what circumstances personalized medicine is cost effective.  In their 2019 scoping review of personalized medicine cost effectiveness, Kasztura et al \cite{kasztura2019cost} found that willingness-to-pay thresholds vary wildly from country to country (citing that cost per quality adjusted life year (QALY) for some modes of personalized medicine range from \$20,000 USD per QALY in Europe and the United Kingdom to \$200,000 USD per QALY in the United States).  This high variability means the burden required for start up may result in a positive return on investment in some areas but not others. This variability should prompt would be adopters to more closely examine whether taking on the initial burden is worth the result.

Others have noted that  much work on personalized medicine has not centred the needs, constraints, and utilities of the patient \cite{rogowski2015concepts, di2017personalized}. Patients can be burdened by frequent followup for clinical measurement (as in the case with warfarin), be burdened by costly expenses related to obtaining care, or may be more risk adverse/tolerant than the ``typical'' patient. As an example, transportation has been found to be a large financial burden for patients receiving cancer treatment \cite{houts1984nonmedical}, and continues to burden patients, with a 2020 study finding that the cost of parking alone can climb as high as \$1600 over the course of treatment in the United States \cite{lee2020assessment}.  Additional visits to a clinic have the potential to further burden patients by requiring them to miss a day of work, and find means of childcare during their absence (if necessary). Incorporating patient preferences and reducing the burden of personalization on the patient can result in sustained adherence \cite{elliott2008understanding}, thereby increasing effectiveness and further preventing adverse events.

The complexity of balancing these burdens means that Implementation decisions made at the organizational level need to attend to a broad array of evidence and contextual factors. Know4Go \cite{martin2016hospital} is one framework for explicitly considering factors from expanded domains of influence surrounding adoption of new technologies/interventions in a healthcare setting (like a clinic or hospital). These expanded domains of influence include: social, legal, ethical, environmental/institutional, political, entrepreneurial/innovative, research opportunity, and reversibility factors in conjunction with objective evidence of benefits versus risks, systematic review, and costs.  Broadly, once evidence has been synthesized through systematic review and/or meta-analysis, the evidence is contextualized to local healthcare system perspective.  Evidence is converted onto a benefit scale, derived from the number of patients likely to benefit from adoption of the technology/intervention.  Budget impact of the adoption is estimated using costing data from the hospital/clinic, and new technologies can be triaged according to their impact and cost.  

Policy decisions around personalization are complex. They carry burden for health systems and patients that vary widely by context. While there are frameworks like Know4Go for navigating these decisions, applying them requires quality evidence for the potential benefits of different kinds of personalization, even for deciding on potential pilot studies. Our framework can produce evidence for the potential effectiveness of a range of modes of personalization to inform organization-level decisions surrounding the investigation and implementation of personalized medicine programs that reduce cost, respect burden, and improve outcomes.


