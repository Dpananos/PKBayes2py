\section{A Framework for Assessing Static and Dynamic Personalization}\label{ss:framework}

In this section, we present a the components of our framework for assessing static and dynamic personalization.  We details for fitting a heirarchical Bayesian pharmacokinetic model to concentration data from a cohort of patients, assessing the behaviour of markov chains via diagnostics, and outline how a Bayesian model can be used to generate simulated data for experimentation.  We note here that the details provided are for a specific drug, but the framework is sufficiently flexible to allow for different pharmacokinetic models for different drugs to be used. We then outline several modes of static and dynamic personalization ranging from no personalization (every patient gets the same dose) to a compelx dynamic mode of personalization (estimation of the optimal policy for dosing from a dynamic treatment regime).  Finally, we outline steps for assessing the benefits of each mode of personalization.

\subsection{Bayesian Modelling}

The first step in our framework is to fit a Bayesian model that relates patient covariates and dose to drug concentration as a function of time. For example, previous work \cite{pananos2020comparisons} describes a hierarchical Bayesian model of apixaban pharmacokinetics, in which the clearance rate (L/hour), time to max concentration (hours), absorption time delay (hours), and ratio between the elimination and absorption rate constants (called alpha, a unitless parameter) are hierarchically modelled.  We extend that model by regressing the latent pharmacokinetic parameters on baseline clinical variables (age, sex, weight, and creatinine) to permit personalization.

The integrals required for all but the simplest Bayesian models are intractable, and so Markov chain monte carlo (MCMC) techniques are often used to approximate the expectations with respect to the posterior distribution.  Presently, the gold standard for generating samples from the posterior is Hamiltonian Monte Carlo (HMC).  Many implementations of HMC come with diagnostics which monitor the behaviour of the Markov chains used to generate samples from the posterior. That these Markov chains behave well is crucial, as any inferences about or from the model are obtained from samples generated by the chains. To assess the quality of the markov chains, several diagnostics are commonly used including: number of divergences, the Gelman-Rubin convergence diagnostic, and effective sample size.  

A divergence in the Markov chain indicates that the HMC Markov chain has encoutered a region of high curvature in the posterior distribution which can not be adequately explored.  Consequently, monte carlo estimators of any expectations can be biased due to incomplete exploration of the posterior distribution.  It is important that none of the Markov chains generated by HMC display a divergence, and that many chains are initialized and are allowed to explore the posterior distribution.

Since several Markov chains are used to generate samples from the posterior, a diagnostic is required to measure of all chains have converged to the same limiting distribution.  The Gelman-Rubin (sometimes called $\hat{R}$) convergence diagnostic is designed to detect if the Markov chains have converged to the same distribution by measuring the within chain variance to the between chain variance. In practice, $1.05<\hat{R}$ indicates that there is poor mixing of the Markov chains and inference from the samples should not be performed lest the monte carlo estimators are biased by this poor mixing.

Assuming the chains do not exhibit divergences and arrive at the same limiting distribution, the Markov chains could exhibit high within chain correlation, thereby increasing uncertaintuy of estimation of keyu posterior quantitites such as (means, variances, or quantiles) [citation in section 15.4 of Stan manual, include that].  The effective sample size is a measure of how much the within chain autocorrelation increases uncertainty estimates.  In some software packages, the effective sample size is reported as a fraction of the total number of samples drawn from the Markov chains.  Presently, the guidance is that the effective sample size ratio should be no smaller than 1\%.

Once the model is fit, important diagnostics indicate no pathelogical behaviour, and the model is deemded to fit the data sufficiently well, the model can then used to generate synthetic pharmacokinetic data for use in experiments to compare different forms of personalization. Each generated data point may be thought of as one synthetic patient, with observed covariates and observed pharmacokinetic parameters. These parameters, which are never observed in real data, allow us to compute the effects of any dosing decisions (which are made \textit{without} direct knowledge of the parameters), and thus allow us to evaluate the performance of different modes of personalized dosing on the sampled population. 

\subsection{Modes of Personalization}

The second step in our framework is to identify modes of personalization that we wish to evaluate. This would typically include both static and dynamic modes of personalization. For example, \textbf{go on about this for a while.}

\subsection{Evaluation}

\textbf{Describe training/testing here I think.}

We compare all methods on their achieved reward as well as the difference between the achieved reward and theoretically largest reward the reward we would achieve if we knew the pharmacokinetic parameters exactly).  Because we know the true latent pharmacokinetic parameters of the simulated subjects, we can optimize the reward with the known pharmacokinetics of the subject, thereby yielding the largest reward possible.