\section{A Framework for Assessing Static and Dynamic Personalization}\label{ss:framework}

In this section, we present a the components of our framework for assessing static and dynamic personalization.  We details for fitting a heirarchical Bayesian pharmacokinetic model to concentration data from a cohort of patients, assessing the behaviour of markov chains via diagnostics, and outline how a Bayesian model can be used to generate simulated data for experimentation.  We note here that the details provided are for a specific drug, but the framework is sufficiently flexible to allow for different pharmacokinetic models for different drugs to be used. We then outline several modes of static and dynamic personalization ranging from no personalization (every patient gets the same dose) to a compelx dynamic mode of personalization (estimation of the optimal policy for dosing from a dynamic treatment regime).  Finally, we outline steps for assessing the benefits of each mode of personalization.

\subsection{Bayesian Modelling}

The first step in our framework is to fit a Bayesian model that relates patient covariates and dose to drug concentration as a function of time. For example, previous work \cite{pananos2020comparisons} describes a hierarchical Bayesian model of apixaban pharmacokinetics, in which the clearance rate (L/hour), time to max concentration (hours), absorption time delay (hours), and ratio between the elimination and absorption rate constants (called alpha, a unitless parameter) are hierarchically modelled.  We extend that model by regressing the latent pharmacokinetic parameters on baseline clinical variables (age, sex, weight, and creatinine) to permit personalization.

The integrals required for all but the simplest Bayesian models are intractable, and so Markov chain monte carlo (MCMC) techniques are often used to approximate the expectations with respect to the posterior distribution.  Presently, the gold standard for generating samples from the posterior is Hamiltonian Monte Carlo (HMC) [citation needed, see our first paper].  Many implementations of HMC come with diagnostics which monitor the behaviour of the Markov chains used to generate samples from the posterior. That these Markov chains behave well is crucial, as any inferences about or from the model are obtained from samples generated by the chains. To assess the quality of the markov chains, several diagnostics are commonly used including: number of divergences, the Gelman-Rubin convergence diagnostic, and effective sample size.  

A divergence in the Markov chain indicates that the HMC Markov chain has encoutered a region of high curvature in the posterior distribution which can not be adequately explored.  Consequently, monte carlo estimators of any expectations can be biased due to incomplete exploration of the posterior distribution.  It is important that none of the Markov chains generated by HMC display a divergence, and that many chains are initialized and are allowed to explore the posterior distribution.

Since several Markov chains are used to generate samples from the posterior, a diagnostic is required to measure of all chains have converged to the same limiting distribution.  The Gelman-Rubin (sometimes called $\hat{R}$) convergence diagnostic is designed to detect if the Markov chains have converged to the same distribution by measuring the within chain variance to the between chain variance. In practice, $1.05<\hat{R}$ indicates that there is poor mixing of the Markov chains and inference from the samples should not be performed lest the monte carlo estimators are biased by this poor mixing.

Assuming the chains do not exhibit divergences and arrive at the same limiting distribution, the Markov chains could exhibit high within chain correlation, thereby increasing uncertaintuy of estimation of keyu posterior quantitites such as (means, variances, or quantiles) [citation in section 15.4 of Stan manual, include that].  The effective sample size is a measure of how much the within chain autocorrelation increases uncertainty estimates.  In some software packages, the effective sample size is reported as a fraction of the total number of samples drawn from the Markov chains.  Presently, the guidance is that the effective sample size ratio should be no smaller than 1\%.

Once the model is fit, important diagnostics indicate no pathelogical behaviour, and the model is deemded to fit the data sufficiently well, the model can then used to generate synthetic pharmacokinetic data for use in experiments to compare different forms of personalization. Each generated data point may be thought of as one synthetic patient, with observed covariates and observed pharmacokinetic parameters. These parameters, which are never observed in real data, allow us to compute the effects of any dosing decisions (which are made \textit{without} direct knowledge of the parameters), and thus allow us to evaluate the performance of different modes of personalized dosing on the sampled population. 

\subsection{Modes of Personalization}

The second step in our framework is to identify modes of personalization that we wish to evaluate. We classify these modes of personalization into two types: statitc and dynamic personalization.

Static modes of personalization seek to inform the dose at one point in time (usually induction) with the goal of eliminating the need for ``trial-and-error'' adjustments.  We consider two modes of static personalization:

\begin{enumerate}
	\item One size fits all.  This mode of personalization is not very pesonal at all.  All patients recieve the same dose size at the onset of treatment.
	\item Doses size selected on clinical variables.  In this mode of personaliztion, the patients age, sex, weight, and creatinine measurements are provided to our pharmacokinetic model.  A dose size is then selected to maximize the reward function conditional on these measurements.
\end{enumerate}

Dynamic modes of personalization seek to personalize the initial doses but also the titration process.  We consider four modes of dynamic personalization:

\begin{enumerate}
	\item One size fits all dose \textit{and} one blood sample.  This mode of personalization provides patients the same dose to start, but requires a concentration measurement to be made someitme in the future.  In our experiments, subjects take their intial dose once every 12 hours with perfect adherence.  In the second half of the fifth day, a concentration measurement is made at a random time.  Our pharmacokinetic model conditions on this measurement, and the dose is adjusted in order to maximize the reward in the latter 5 days.
	
	\item Dose size selected on clinical variables \textit{and} one blood sample.  Here, the initial dose provided to the patient is determiend by the patient's clinical measurements.  The patient's blood concentration is observed in the latter half of the fifth day.  The model is conditioned on this concentration and the dose is adjusted to optimize the reward.
	
	\item Optimal sampling.  Similar to the previous mode of personalization, but the time at which the measurement is made is under our control.
	
	\item Q-learning. Estimation of the optimal policty to maximize the reward function via a dynamic treatment regime and Q-learning.
\end{enumerate}

Here, we stress that these are just examples of some modes of personalization, and that we do not mean that these modes should always be candidate modes for personalizAtion .  These modes may not be appropriate for all drugs across all clinics, and were selected in order to illustrate natural extensions and combinations of static personalization with additional information collection.

\subsection{Evaluation}

We compare all methods on their achieved reward as well as the difference between the achieved reward and theoretically largest reward the reward we would achieve if we knew the pharmacokinetic parameters exactly).  Because we know the true latent pharmacokinetic parameters of the simulated subjects, we can optimize the reward with the known pharmacokinetics of the subject, thereby yielding the largest reward possible.

At the time of dose adjustment, the actual reward is not known.  However, because a Bayesian model is a generative model, samples generated from that model can be used to compute the exepcted reward.  The steps for computing the expected reward for a given dose are as follows:

\begin{enumerate}
	\item Condition the model on available information if the mode of personalization permits so.  For some modes of personalization, this might be clinical measurements, blood concentration measurements, both or neither.
	
	\item Draw a set of pharmacokinetic paramteters from the posterior distribution. The pharmacokinetic parameters in conjuntion with the dose schedule completely determine the concentration profile, allowing us to make predictions of patients concentration into the future.
	
	\item Compute the concentration profile on a grid of times.  The grid must be sufficiently coarse to capture changes in the concentration over time.  We make a prediction at 15 minute intervals.
	
	\item Compute the reward for the proposed dose.
	
	\item Update the proposed dose and recompute the reward.
\end{enumerate}

The concentration profile scales linearly with dose size; double the dose, double the concentration at a given time.  This relationship allows for off the shelf optimizers to be used in the selection of dose size in this processes.
