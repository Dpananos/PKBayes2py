\section{Discussion}\label{ss:discussion}

%Including age, sex, weight, and creatinine in our Bayesian model improved the inferences from that model.  Though the predicted concentrations and estimates of uncertainty changed negligibly, the covariates explained residual confounding in the random effects. This results in a model which better explains the observed variation in the data and hence should generate more plausible data for simulation.

In the following, we discuss the results of our case study, followed by a discussion of the broader potential implications of personalized medicine policy.

%Working subsection titles - not sure if they stay
\subsection{Comparing Modes of Personalization}

As expected, modes of personalization which use more information result in larger reward. However, if we consider the expected reward of the different modes, there is diminishing return on investment observed when using additional information (and consequently, taking on additional implementation burden to effectively use that information). 

\textcolor{red}{I wonder if we can make a clearer, more quantitative argument in terms of why. One way is to make it conditional -- if we care about xx the most, then we would do yy. On the other hand, if we care about yy, maybe we would do... This is easier to sell than "I would recommend this." You can even phrase it as like, unless you care super a lot about that last 1\% of reward, realistically you should just do xx. So, this is just about framing.}Were doses to be personalized for the simulated population, we would recommend the covariate model be used, as it is easier to implement, puts smaller burden on the clinic, and results in approximately mean/median rewards as compared to other methods.  Taking an additional sample doesn’t seem to improve the expected mean/median reward appreciably to be worth the burden of having the patient take time to come in, drawing their blood, measuring their concentration in the lab, and reporting results to the decision maker, in which a decision to not adjust the dose might be made anyway. Similar arguments can be made for Q learning, which has even higher implementation burden.

But mean/median reward does not tell the whole story.  As noted, the distribution of differences in reward is right skewed.  Some subjects have a very large difference, and the possibility of these differences might not be acceptable in different contexts with different drugs.  There is a tradeoff between less extreme differences and taking on additional clinic and implementation burden, and that tradeoff should be examined on a case by case basis.

Context is crucial, and how we adapt to that context is perhaps a question in need of closer examination.  Traditional methods of personalization include conditioning only on a subject’s covariates (not unlike the Covariate model we present here).  But of course patients are not their age, sex, weight, and creatinine.  Additionally, safety information and best available practices might change in the future as more research on drugs is performed. Were new safety information to be published, one might imagine the reward function might be affected, which may result in a new mode of personalization being more/less preferable or more/less feasible.  Any number of factors in flux can change the context in which personalization occurs, and that change in context may prompt for a re-evaluation in how personalization is done.

Thus, our results are not about apixaban per se.  We don’t offer recommendations on how personalization for apixaban should be done because we can’t anticipate the context.  What we offer is a framework for developing strategies of personalization and evaluating their performance against their implementation and clinic burden.  Context can be changed where needed, either through the reward function, or by adjusting when the clinic is able to take measurements, or by including additional information such as genotype in the Bayesian model.  Using this framework, clinics have flexibility to personalize the personalization.

\textcolor{red}{Would like to add a section that describes what would have produced different results. E.g., if the covariates weren't as helpful in determining underlying parameters, then maybe dynamic personalization would have a bigger advantage relative to static? And if measurement time was very critical we would see an advantage there?}

%Working subsection titles - not sure if they stay
\subsection{Relating Results to Policy Decisions}

Personalized medicine still faces several barriers to widespread adoption, including economic burden, patient burden, and expertise burden required for new methods of personalization.
Personalized medicine can increase safety and reduce costs to the healthcare system by identifying patients who are at greater risk for adverse events or dose adjustments.  For example, if personalization enables a patient to avoid an adverse event, then this avoids associated costs to the healthcare system, example from a hospital stay \cite{looff2016economic}.  More ambitiously, personalized medicine has the potential to save the healthcare system costs by more effectively using resources \cite{shabaruddin2015economic}. 

The cost of instruments, technicians, and leadership required to operate a personalized medicine clinic are high burden, and it is not yet clear if personalized medicine is sufficiently cost effective to offset operating costs in all circumstances \cite{kasztura2019cost}.  In their 2019 scoping review of personalized medicine cost effectiveness, Kasztura et. al \cite{kasztura2019cost} found that willingness-to-pay thresholds vary wildy from country to country (citing that cost per quality adjusted life year for some modes of personalized medicine range from \$20, 000 USD per quality adjusted life year in for studies in Europe and the United Kingdom to \$200,000 USD per quality adjusted life year for studies in the United States).  This high variability in cost effectiveness means the burden required for start up may result in a positive return on investment in some areas but not others. This variability should prompt would be adopters to more closely examine if taking on the initial burden is worth the result.

% beef up here
% Examples.  Identifty clear examples from the literature around diagnostics?
The dominant perspective on personalized medicine focuses on the use of clinical and physiological information (including biomarkers, genotyping, and diagnostic tests) as a means of optimizing treatments, but largely ignore needs, constraints, and utilities of the patient \cite{rogowski2015concepts, di2017personalized}. Patients can be burdened by frequent followup for clinical measurement (as in the case with Warfarin), be burdened by costly expenses related to obtaining care, or may be more risk adverse/tolerant than the ``typical'' patient. As an example, transportation has been found to be a large financial burden for patients recieving cancer treatment \cite{houts1984nonmedical}, and continues to burden patients, with a 2020 study finding that the cost of parking alone can climb as high as \$1600 over the course of treatment in the United States \cite{lee2020assessment}.  Additional visits to a clinic have the potential to further burden patients by requiring them to miss a day of work, and find means of childcare during their absence (if neccesary). Incorporating patient preferences and reducing the burden of personalization on the patient can result in sustained adherence \cite{elliott2008understanding}, thereby increasing effectiveness and further preventing adverse events.

% FInd some machine learning cautinary tales

An additional expertise burden is added as machine learning (used interchangeably with the term “artificial intelligence”) is adopted into personalized medicine initiatives.  Cutting edge machine learning models for prediction or decision making can be prohibitively burdensome to implement effectively. Failure to carefully implement a prediction model may result in pernicious bias inadvertently affecting subpopulations, as was found to be the case in algorithms for credit scoring \cite{barocas2016big}, crime prediction \cite{lum2016predict}, and hiring \cite{ajunwa2020paradox}.  A 2019 study found an instance of this bias in a widely used risk scoring algorithm in healthcare \cite{obermeyer2019dissecting}, demonstrating that despite the best intentions of those involved, the use of a model can lead to worse rather than better care if investigators are not careful in considering what sorts of bias may be present in the data used to train these models.  Implementation of new approaches and methods requires the close collaboration of experts in data science  with physicians, domain experts, and other stakeholders.  Close collaboration should allow for domain experts to identify what kinds of biases the data might have, and for data science experts to implement methods to help ammeliorate that bias (or to admit the data are not fit for purpose).  The result of iterating on this collaborative process (wherein domain experts help inform the appraoches methodologists take, and the methodologists provide model checks which help domain experts decide if decisions from the model are reasonable or suspicious) is a model which more closely aligns with domain expertise, a model which is sufficiently flexible to capture the true data generating mechanism, an effective use of data, a more transparent modelling process, and calibrated expectations surrounding algorithms and their abilities \cite{frohlich2018hype}.  Presently, this form of collaboration between methodologists and domain experts is not the norm, with developement of machine learning solutions in healthcare bdeing developed in silos \cite{wiens2019no}.

These burdens may be surmountable for some, but the question then turns to if the result is worth the expense.  Answering that question is difficult without an idea how the additional burden of collecting data, or implementing new algorithms, will benefit the clinic or the patient subject to inherent constraints. 

{\color{red}
I think this would be a good place to explain a bit about how this could feed into tools that are used for policy decisions. Like for example Janet's Know4Go. So a paragraph that says like

- Implementation decisions made at the organizational level need to attend to a broad array of evidence and contextual factors

- Know4Go [cite] is one such framework; broadly it works like this... couple of sentences explaining

- Our framework could produce evidence that is used in this framework to inform organization-level decisions.
}

\subsection{Limitations}

We’ve examined six modes for making decisions.  The next mode improves on a deficiency of the previous mode in a natural manner, and so our experiment constitutes a kind of ablation study.  We believe the decision making aspect of our study extracts information in a responsible way and uses the best decision making methodology available.  That being said, the experiment is not without limitations.

The bayesian model of the pharmacokinetics is integral to the methodology we present.  Any shortcomings in the model affect the quality of the decision and decision process.  Bayesian models are not as ubiquitous as other models in pharmacology, and so particular expertise is required for model development and evaluation.  That expertise increases the implementation burden of any decision process involving Bayesian models.  However, we demonstrate how one such model can be constructed in a past stdy [CITE] and include open sourced code and data for practitioners to replicate our model fitting.

Additionally, the data required to construct a high quality Bayesian model of pharmacokinetics require multiple observations of a single patient over an extended time, preferably over multiple well timed doses with near perfect adherence.  Obtaining such data requires well organized efforts and is high burden for both investigators and participating subjects.  This makes acquiring a robust Bayesian model for use in dose personalization difficult.

\subsection{Future Work}

Because the data required to build reliable Bayesian pharmacokinetic models are difficult to collect in practice, research into developing these models from observational data may prove fruitful in extending this work. If clinics record data on measured blood concentrations, they may have dozens or hundreds of subjects with only one or two measurements per subject.  Moreover, the subjects in question may be on multiple drugs or have comorbidities which may affect the pharmacokinetics of the drug under study.  Additional research into constructing Bayesian models which can adjust for polypharmacy and comorbidities while learning an individual’s pharmacokinetics from a large but sparse sample would drive this work towards being easier to implement in practice.


